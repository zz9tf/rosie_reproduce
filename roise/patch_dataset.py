#!/usr/bin/env python3
"""
Patch-based Image Dataset for H&E to multiplex protein prediction.

è¿™ä¸ªæ¨¡å—å®ç°äº†åŸºäºpatchçš„å›¾åƒæ•°æ®é›†ï¼Œæ”¯æŒå°†å¤§å°ºå¯¸å›¾åƒè‡ªåŠ¨åˆ‡åˆ†ä¸ºéé‡å çš„patchesè¿›è¡Œè®­ç»ƒã€‚
"""

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import cv2
from typing import Tuple, List, Dict, Optional
import pyarrow.parquet as pq
import zarr

# é»˜è®¤é…ç½®
DEFAULT_PATCH_SIZE = 128
DEFAULT_BATCH_SIZE = 32
DEFAULT_NUM_WORKERS = 4

def load_image(image_path: str) -> np.ndarray:
    """
    åŠ è½½å›¾åƒæ–‡ä»¶å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„ã€‚
    
    Args:
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
        
    Returns:
        å›¾åƒçš„numpyæ•°ç»„ï¼Œå½¢çŠ¶ä¸º (H, W, C)
    """
    # æ”¯æŒå¤šç§å›¾åƒæ ¼å¼
    if image_path.lower().endswith(('.tiff', '.tif')):
        # ä½¿ç”¨cv2åŠ è½½TIFFæ–‡ä»¶
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        if image is not None:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    else:
        # ä½¿ç”¨PILåŠ è½½å…¶ä»–æ ¼å¼
        image = Image.open(image_path).convert('RGB')
        image = np.array(image)
    
    if image is None:
        raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
    
    return image

def load_patch_from_zarr(zarr_path: str, image_idx: int, center_x: int, center_y: int, 
                        patch_size: int = 128) -> np.ndarray:
    """
    ä»zarræ•°ç»„ä¸­ç›´æ¥æå–æŒ‡å®šä½ç½®çš„å›¾åƒå—
    
    Args:
        zarr_path: zarræ–‡ä»¶è·¯å¾„
        image_idx: å›¾åƒç´¢å¼•
        center_x: ä¸­å¿ƒç‚¹xåæ ‡
        center_y: ä¸­å¿ƒç‚¹yåæ ‡
        patch_size: patchå¤§å°
        
    Returns:
        æå–çš„å›¾åƒå— (patch_size, patch_size, 3)
    """
    try:
        # æ‰“å¼€zarræ•°ç»„
        zarr_array = zarr.open(zarr_path, mode='r')
        
        # è¯»å–å®Œæ•´å›¾åƒ
        image = zarr_array[image_idx]  # (H, W, 3)
        H, W, C = image.shape
        
        # è®¡ç®—patchè¾¹ç•Œ
        half_size = patch_size // 2
        x0 = max(0, center_x - half_size)
        y0 = max(0, center_y - half_size)
        x1 = min(W, center_x + half_size)
        y1 = min(H, center_y + half_size)
        
        # æå–patch
        patch = image[y0:y1, x0:x1, :]
        
        # å¦‚æœpatchå°äºæŒ‡å®šå¤§å°ï¼Œè¿›è¡Œpadding
        if patch.shape[0] < patch_size or patch.shape[1] < patch_size:
            padded_patch = np.zeros((patch_size, patch_size, C), dtype=patch.dtype)
            padded_patch[:patch.shape[0], :patch.shape[1], :] = patch
            patch = padded_patch
        
        return patch
        
    except Exception as e:
        raise ValueError(f"ä»zarræå–patchå¤±è´¥: {e}")

def get_zarr_traceback_info(row: pd.Series, marker: str = 'HE') -> Dict[str, any]:
    """
    ä»DataFrameè¡Œä¸­è·å–zarrè¿½æº¯ä¿¡æ¯
    
    Args:
        row: DataFrameä¸­çš„ä¸€è¡Œæ•°æ®
        marker: è¦è¿½æº¯çš„markeråç§°
        
    Returns:
        åŒ…å«zarrä½ç½®ä¿¡æ¯çš„å­—å…¸
    """
    zarr_path = row.get(f'{marker}_zarr_path', '')
    image_idx = row.get(f'{marker}_image_idx', -1)
    
    if not zarr_path or image_idx == -1:
        return {
            'zarr_path': '',
            'image_idx': -1,
            'center_x': row.get('center_x', -1),
            'center_y': row.get('center_y', -1),
            'error': f'Marker {marker} çš„è¿½æº¯ä¿¡æ¯ä¸å®Œæ•´'
        }
    
    return {
        'zarr_path': zarr_path,
        'image_idx': int(image_idx),
        'center_x': int(row.get('center_x', -1)),
        'center_y': int(row.get('center_y', -1))
    }

class PatchImageDataset(Dataset):
    """
    åŸºäºä¸­å¿ƒç‚¹çš„patchå›¾åƒæ•°æ®é›†ç±»ã€‚
    
    æ ¹æ®DataFrameä¸­è®°å½•çš„ä¸­å¿ƒç‚¹åæ ‡æå–128x128çš„patchesï¼Œæ¯ä¸ªpatchå¯¹åº”ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ã€‚
    æ”¯æŒä»zarræ•°ç»„ç›´æ¥åŠ è½½æ•°æ®ä»¥æé«˜é€Ÿåº¦ã€‚
    
    Args:
        parquet_path: parquetæ–‡ä»¶è·¯å¾„
        root_dir: å›¾åƒæ–‡ä»¶çš„æ ¹ç›®å½•ï¼ˆå½“use_zarr=Falseæ—¶ä½¿ç”¨ï¼‰
        patch_size: patchçš„å¤§å° (é»˜è®¤: 128)
        transform: å›¾åƒå˜æ¢
        target_biomarkers: ç›®æ ‡ç”Ÿç‰©æ ‡è®°ç‰©åˆ—è¡¨
        cache_images: æ˜¯å¦ç¼“å­˜å›¾åƒåˆ°å†…å­˜
        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼‰
        row_group_size: æ¯æ¬¡è¯»å–çš„è¡Œç»„å¤§å°
        use_zarr: æ˜¯å¦ä½¿ç”¨zarrç›´æ¥åŠ è½½ï¼ˆé»˜è®¤: Trueï¼‰
        zarr_marker: ç”¨äºåŠ è½½å›¾åƒçš„markeråç§°ï¼ˆé»˜è®¤: 'HE'ï¼‰
    """
    
    def __init__(self,
                parquet_path: str,
                root_dir: str = None,
                patch_size: int = DEFAULT_PATCH_SIZE,
                transform: Optional[Dict] = None,
                target_biomarkers: Optional[List[str]] = None,
                cache_images: bool = False,
                row_group_size: int = 10000,
                subset: Optional[List[str]] = None,
                use_zarr: bool = True,
                zarr_marker: str = 'HE'):
        
        self.parquet_path = parquet_path
        self.root_dir = root_dir
        self.patch_size = patch_size
        self.transform = transform
        self.cache_images = cache_images
        self.image_cache = {}  # å›¾åƒç¼“å­˜
        self.target_biomarkers = target_biomarkers
        self.row_group_size = row_group_size
        self.subset = subset
        self.use_zarr = use_zarr
        self.zarr_marker = zarr_marker
        self.zarr_cache = {}  # zarræ•°ç»„ç¼“å­˜
        self.subset_indices = None  # åˆå§‹åŒ–subset_indices
        
        # åˆå§‹åŒ–parquetæ–‡ä»¶
        self._init_parquet_file()
        
        # è·å–ç”Ÿç‰©æ ‡è®°ç‰©ä¿¡æ¯
        self._setup_biomarkers()
        
        # å¤„ç†subsetè¿‡æ»¤
        if self.subset is not None:
            self._setup_subset_indices()
        
        print(f"ğŸ“Š æµå¼æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ§¬ ç›®æ ‡ç”Ÿç‰©æ ‡è®°ç‰©: {self.target_biomarkers}")
        print(f"ğŸ§¬ è¾“å‡ºé€šé“æ•°: {len(self.target_biomarkers) * 3} (RGB for each biomarker)")
        print(f"ğŸ“ˆ æ€»è¡Œæ•°: {self.total_rows}")
        print(f"ğŸš€ æ•°æ®åŠ è½½æ–¹å¼: {'Zarrç›´æ¥åŠ è½½' if self.use_zarr else 'å›¾åƒæ–‡ä»¶åŠ è½½'}")
        if self.use_zarr:
            print(f"ğŸ¯ Zarr marker: {self.zarr_marker}")
        if self.subset is not None:
            print(f"ğŸ“‹ å­é›†è¿‡æ»¤: {len(self.subset)} ä¸ªID")
    
    def _init_parquet_file(self):
        """åˆå§‹åŒ–parquetæ–‡ä»¶"""
        if not os.path.exists(self.parquet_path):
            raise FileNotFoundError(f"Parquetæ–‡ä»¶ä¸å­˜åœ¨: {self.parquet_path}")
        
        # æ‰“å¼€parquetæ–‡ä»¶
        self.parquet_file = pq.ParquetFile(self.parquet_path)
        self.total_rows = self.parquet_file.metadata.num_rows
        
        # è·å–åˆ—ä¿¡æ¯
        self.schema = self.parquet_file.schema
        self.column_names = [field.name for field in self.schema]
        
        print(f"âœ… æˆåŠŸæ‰“å¼€parquetæ–‡ä»¶: {self.parquet_path}")
        print(f"ğŸ“Š æ€»è¡Œæ•°: {self.total_rows:,}")
        print(f"ğŸ“‹ åˆ—å: {self.column_names}")
    
    def _setup_biomarkers(self):
        """è®¾ç½®ç”Ÿç‰©æ ‡è®°ç‰©åˆ—å"""
        # ä»åˆ—åä¸­æ¨æ–­æ‰€æœ‰å¯ç”¨çš„ç”Ÿç‰©æ ‡è®°ç‰©
        exclude_cols = {'image_path', 'center_x', 'center_y', 'image_id', 'patient_id', 'block', 'core_group_x', 'core_group_y'}
        exclude_cols.update({col for col in self.column_names if col.endswith('_image_path')})
        exclude_cols.update({col for col in self.column_names if col.endswith('_zarr_path')})
        exclude_cols.update({col for col in self.column_names if col.endswith('_image_idx')})
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯RGBæ ¼å¼çš„åˆ—ï¼ˆå¦‚ CD3_R, CD3_G, CD3_Bï¼‰
        rgb_columns = [col for col in self.column_names if col.endswith('_R') or col.endswith('_G') or col.endswith('_B')]
        
        if rgb_columns:
            # æå–æ‰€æœ‰å¯ç”¨çš„markeråç§°ï¼ˆå»æ‰_R, _G, _Båç¼€ï¼‰
            available_markers = set()
            for col in rgb_columns:
                marker = col.rsplit('_', 1)[0]  # å»æ‰æœ€åä¸€ä¸ªä¸‹åˆ’çº¿åçš„éƒ¨åˆ†
                available_markers.add(marker)
            self.available_rgb_biomarkers = sorted(list(available_markers))
            print(f"ğŸ¨ æ£€æµ‹åˆ°RGBæ ¼å¼çš„ç”Ÿç‰©æ ‡è®°ç‰©: {self.available_rgb_biomarkers}")
        else:
            self.available_rgb_biomarkers = []
        
        # ä¼ ç»Ÿæ ¼å¼ï¼šç›´æ¥ä½¿ç”¨åˆ—åä½œä¸ºç”Ÿç‰©æ ‡è®°ç‰©
        self.available_non_rgb_biomarkers = [col for col in self.column_names if (col not in exclude_cols) and (col not in rgb_columns)]
        if self.available_non_rgb_biomarkers:
            print(f"ğŸ“Š æ£€æµ‹åˆ°ä¼ ç»Ÿæ ¼å¼çš„ç”Ÿç‰©æ ‡è®°ç‰©: {self.available_non_rgb_biomarkers}")
        
        if len(self.available_rgb_biomarkers) == 0 and len(self.available_non_rgb_biomarkers) == 0:
            raise ValueError("æœªæ‰¾åˆ°ç”Ÿç‰©æ ‡è®°ç‰©æ ‡ç­¾åˆ—")
        
        # è®¾ç½®ç›®æ ‡ç”Ÿç‰©æ ‡è®°ç‰©
        if self.target_biomarkers is None:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ç”Ÿç‰©æ ‡è®°ç‰©
            self.target_biomarkers = self.available_rgb_biomarkers + self.available_non_rgb_biomarkers
        else:
            # éªŒè¯æŒ‡å®šçš„ç”Ÿç‰©æ ‡è®°ç‰©æ˜¯å¦å¯ç”¨
            missing_markers = [marker for marker in self.target_biomarkers if marker not in self.available_rgb_biomarkers and marker not in self.available_non_rgb_biomarkers]
            if missing_markers:
                raise ValueError(f"æŒ‡å®šçš„ç”Ÿç‰©æ ‡è®°ç‰©ä¸å­˜åœ¨: {missing_markers}")
        
        self.rgb_target = []
        self.non_rgb_target = []
        for marker in self.target_biomarkers:
            if marker in self.available_rgb_biomarkers:
                self.rgb_target.append(marker)
            else:
                self.non_rgb_target.append(marker)
        
        print(f"âœ… ä½¿ç”¨ç›®æ ‡ç”Ÿç‰©æ ‡è®°ç‰©: {self.target_biomarkers}")
    
    def _setup_subset_indices(self):
        """è®¾ç½®å­é›†ç´¢å¼•ï¼Œç”¨äºè¿‡æ»¤æ•°æ®"""
        if self.subset is None:
            self.subset_indices = None
            return
        
        print(f"ğŸ” æ­£åœ¨å¤„ç†å­é›†è¡Œç´¢å¼•...")
        
        # å°†subsetè½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•
        try:
            # å°è¯•å°†subsetä¸­çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•
            self.subset_indices = [int(idx) for idx in self.subset]
        except ValueError:
            print("âš ï¸ é”™è¯¯: subsetä¸­çš„å€¼æ— æ³•è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•")
            print("è¯·ç¡®ä¿subsetåŒ…å«çš„æ˜¯è¡Œç´¢å¼•ï¼ˆæ•´æ•°ï¼‰ï¼Œä¾‹å¦‚: [0, 1, 2, 100, 200]")
            self.subset_indices = None
            return
        
        # éªŒè¯ç´¢å¼•æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
        valid_indices = [idx for idx in self.subset_indices if 0 <= idx < self.total_rows]
        if len(valid_indices) != len(self.subset_indices):
            invalid_count = len(self.subset_indices) - len(valid_indices)
            print(f"âš ï¸ è­¦å‘Š: {invalid_count} ä¸ªç´¢å¼•è¶…å‡ºèŒƒå›´ [0, {self.total_rows-1}]ï¼Œå·²è¿‡æ»¤")
        
        self.subset_indices = valid_indices
        print(f"âœ… æœ‰æ•ˆå­é›†ç´¢å¼•: {len(self.subset_indices)} ä¸ª")
        
    
    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†å¤§å°"""
        if self.subset_indices is not None:
            return len(self.subset_indices)
        return self.total_rows
    
    def __getitem__(self, idx: int) -> Optional[Tuple]:
        """
        æ ¹æ®ç´¢å¼•ä»parquetæ–‡ä»¶ä¸­è¯»å–æ•°æ®å¹¶æå–patchã€‚
        
        Returns:
            Tuple: (patch_tensor, expression_values, valid_mask, center_x, center_y, image_idx)
        """
        if idx >= len(self):
            return None
        
        try:
            # å¦‚æœæœ‰å­é›†ç´¢å¼•ï¼Œä½¿ç”¨å­é›†ç´¢å¼•
            if self.subset_indices is not None:
                actual_idx = self.subset_indices[idx]
            else:
                actual_idx = idx
            
            # è®¡ç®—è¡Œç»„ç´¢å¼•
            row_group_idx = actual_idx // self.row_group_size
            if row_group_idx >= self.parquet_file.num_row_groups:
                return None
            
            # ä½¿ç”¨pyarrowè¯»å–è¡Œç»„æ•°æ®
            batch_table = self.parquet_file.read_row_group(row_group_idx)
            batch_df = batch_table.to_pandas()
            
            # è·å–å½“å‰è¡Œåœ¨batchä¸­çš„ç´¢å¼•
            local_idx = actual_idx % self.row_group_size
            if local_idx >= len(batch_df):
                return None
            
            row = batch_df.iloc[local_idx]
            center_x = int(row['center_x'])
            center_y = int(row['center_y'])
            
            # æ ¹æ®é…ç½®é€‰æ‹©åŠ è½½æ–¹å¼
            if self.use_zarr:
                # ä½¿ç”¨zarrç›´æ¥åŠ è½½
                patch = self._load_patch_from_zarr(row, center_x, center_y)
            else:
                # ä½¿ç”¨ä¼ ç»Ÿå›¾åƒæ–‡ä»¶åŠ è½½
                patch = self._load_patch_from_image_file(row, center_x, center_y)
            
            # å¤„ç†æ ‡ç­¾
            exp_vec, valid_mask = self._process_labels(row)
            
            # åº”ç”¨å˜æ¢
            patch_tensor = self._apply_transforms(patch)
            
            return (patch_tensor, exp_vec, valid_mask, center_x, center_y, idx)
            
        except Exception as e:
            print(f"âš ï¸ Error loading patch (idx: {idx}): {e}")
            return None
    
    def _load_image(self, image_path: str) -> np.ndarray:
        """åŠ è½½å›¾åƒï¼ˆæ”¯æŒç¼“å­˜ï¼‰"""
        if self.cache_images and image_path in self.image_cache:
            return self.image_cache[image_path]
        
        image = load_image(image_path)
        
        if self.cache_images:
            self.image_cache[image_path] = image
        
        return image
    
    def _load_patch_from_zarr(self, row: pd.Series, center_x: int, center_y: int) -> np.ndarray:
        """ä»zarræ•°ç»„åŠ è½½patch"""
        # è·å–zarrè¿½æº¯ä¿¡æ¯
        traceback_info = get_zarr_traceback_info(row, self.zarr_marker)
        
        if 'error' in traceback_info:
            raise ValueError(f"Zarrè¿½æº¯ä¿¡æ¯ä¸å®Œæ•´: {traceback_info['error']}")
        
        zarr_path = traceback_info['zarr_path']
        image_idx = traceback_info['image_idx']
        
        # æ£€æŸ¥zarrç¼“å­˜
        cache_key = f"{zarr_path}_{image_idx}"
        if cache_key in self.zarr_cache:
            zarr_array = self.zarr_cache[cache_key]
        else:
            zarr_array = zarr.open(zarr_path, mode='r')
            if self.cache_images:
                self.zarr_cache[cache_key] = zarr_array
        
        # ç›´æ¥æå–patch
        patch = load_patch_from_zarr(zarr_path, image_idx, center_x, center_y, self.patch_size)
        
        return patch
    
    def _load_patch_from_image_file(self, row: pd.Series, center_x: int, center_y: int) -> np.ndarray:
        """ä»å›¾åƒæ–‡ä»¶åŠ è½½patchï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰"""
        # å¤„ç†å›¾åƒè·¯å¾„
        image_path_str = row['image_path']
        image_path = os.path.join(self.root_dir, image_path_str)
        
        # åŠ è½½å›¾åƒ
        image = self._load_image(image_path)
        height, width = image.shape[:2]
        
        # è®¡ç®—patchçš„è¾¹ç•Œï¼Œç¡®ä¿ä¸è¶…å‡ºå›¾åƒèŒƒå›´
        half_patch = self.patch_size // 2
        x_start = max(0, center_x - half_patch)
        y_start = max(0, center_y - half_patch)
        x_end = min(width, center_x + half_patch)
        y_end = min(height, center_y + half_patch)
        
        # æå–patch
        patch = image[y_start:y_end, x_start:x_end]
        
        # å¦‚æœpatchå°ºå¯¸ä¸è¶³ï¼Œè¿›è¡Œpadding
        if patch.shape[:2] != (self.patch_size, self.patch_size):
            patch = self._pad_patch(patch, center_x, center_y, width, height)
        
        return patch
    
    def _get_image_path_for_marker(self, row: pd.Series, marker: str) -> str:
        """è·å–æŒ‡å®šmarkerçš„å›¾åƒè·¯å¾„"""
        # é¦–å…ˆå°è¯•markerç‰¹å®šçš„è·¯å¾„
        marker_path_col = f'{marker}_image_path'
        if marker_path_col in row and pd.notna(row[marker_path_col]) and row[marker_path_col] != '':
            return os.path.join(self.root_dir, row[marker_path_col])
        
        # å¦‚æœmarkerç‰¹å®šè·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨é€šç”¨è·¯å¾„
        if 'image_path' in row and pd.notna(row['image_path']) and row['image_path'] != '':
            return os.path.join(self.root_dir, row['image_path'])
        
        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ''
    
    def _pad_patch(self, patch: np.ndarray, center_x: int, center_y: int, 
                   image_width: int, image_height: int) -> np.ndarray:
        """
        å¯¹patchè¿›è¡Œpaddingï¼Œç¡®ä¿å°ºå¯¸ä¸ºpatch_size x patch_sizeã€‚
        
        Args:
            patch: åŸå§‹patch
            center_x: ä¸­å¿ƒç‚¹xåæ ‡
            center_y: ä¸­å¿ƒç‚¹yåæ ‡
            image_width: å›¾åƒå®½åº¦
            image_height: å›¾åƒé«˜åº¦
            
        Returns:
            å¡«å……åçš„patchï¼Œå°ºå¯¸ä¸º (patch_size, patch_size, channels)
        """
        current_height, current_width = patch.shape[:2]
        
        if current_height == self.patch_size and current_width == self.patch_size:
            return patch
        
        # è®¡ç®—éœ€è¦çš„padding
        half_patch = self.patch_size // 2
        
        # è®¡ç®—patchçš„ç†æƒ³è¾¹ç•Œ
        x_start = center_x - half_patch
        y_start = center_y - half_patch
        x_end = center_x + half_patch
        y_end = center_y + half_patch
        
        # è®¡ç®—å„è¾¹çš„padding
        pad_left = max(0, -x_start)      # å¦‚æœx_start < 0ï¼Œéœ€è¦å·¦ä¾§padding
        pad_right = max(0, x_end - image_width)  # å¦‚æœx_end > image_widthï¼Œéœ€è¦å³ä¾§padding
        pad_top = max(0, -y_start)       # å¦‚æœy_start < 0ï¼Œéœ€è¦é¡¶éƒ¨padding
        pad_bottom = max(0, y_end - image_height)  # å¦‚æœy_end > image_heightï¼Œéœ€è¦åº•éƒ¨padding
        
        # åº”ç”¨padding
        if patch.ndim == 3:
            pad_shape = ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0))
        else:
            pad_shape = ((pad_top, pad_bottom), (pad_left, pad_right))
        
        # ä½¿ç”¨å›¾åƒçš„æœ€å°å€¼è¿›è¡Œpaddingï¼ˆé€šå¸¸æ˜¯0æˆ–255ï¼‰
        pad_value = 0 if patch.dtype == np.uint8 else patch.min()
        padded_patch = np.pad(patch, pad_shape, mode='constant', constant_values=pad_value)
        
        # ç¡®ä¿patchå°ºå¯¸æ­£ç¡®
        padded_patch = padded_patch[:self.patch_size, :self.patch_size]
        
        return padded_patch
    
    def _process_labels(self, row: pd.Series) -> Tuple[np.ndarray, np.ndarray]:
        """å¤„ç†æ ‡ç­¾æ•°æ®"""
        # è®¡ç®—è¾“å‡ºç»´åº¦
        rgb_output_dim = len(self.rgb_target) * 3
        non_rgb_output_dim = len(self.non_rgb_target)
        total_output_dim = rgb_output_dim + non_rgb_output_dim
        
        # åˆå§‹åŒ–è¾“å‡ºå‘é‡
        exp_vec = np.zeros(total_output_dim, dtype=np.float32)
        valid_mask = np.zeros(total_output_dim, dtype=bool)
        
        # å¤„ç†RGBæ ¼å¼çš„markers
        if self.rgb_target:
            rgb_cols = []
            for marker in self.rgb_target:
                rgb_cols.extend([f"{marker}_R", f"{marker}_G", f"{marker}_B"])
            
            rgb_values = np.array([row[col] if not pd.isna(row[col]) else 0.0 for col in rgb_cols], dtype=np.float32)
            rgb_valid = np.array([not pd.isna(row[col]) for col in rgb_cols], dtype=bool)
            
            exp_vec[:rgb_output_dim] = rgb_values
            valid_mask[:rgb_output_dim] = rgb_valid
        
        # å¤„ç†éRGBæ ¼å¼çš„markers
        if self.non_rgb_target:
            non_rgb_values = np.array([row[col] if not pd.isna(row[col]) else 0.0 for col in self.non_rgb_target], dtype=np.float32)
            non_rgb_valid = np.array([not pd.isna(row[col]) for col in self.non_rgb_target], dtype=bool)
            
            exp_vec[rgb_output_dim:] = non_rgb_values
            valid_mask[rgb_output_dim:] = non_rgb_valid
        
        return exp_vec, valid_mask
    
    def _apply_transforms(self, patch: np.ndarray) -> torch.Tensor:
        """åº”ç”¨å›¾åƒå˜æ¢"""
        if self.transform is not None:
            # è®¾ç½®éšæœºç§å­
            seed = np.random.randint(2**32)
            np.random.seed(seed)
            torch.manual_seed(seed)
            
            if isinstance(self.transform, dict):
                # åˆ†æ­¥éª¤å˜æ¢
                patch_tensor = self.transform['all_channels'](patch)
                patch_final = self.transform['image_only'](patch_tensor)
            else:
                patch_final = self.transform(patch)
        else:
            # é»˜è®¤å˜æ¢
            patch_final = torch.from_numpy(patch.transpose(2, 0, 1)).float() / 255.0
        
        return patch_final

def get_default_transforms():
    """è·å–é»˜è®¤çš„æ•°æ®å˜æ¢"""
    transform_train = {
        'all_channels': transforms.Compose([
            transforms.ToTensor(),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.Resize(224, antialias=True),
            transforms.RandomRotation(degrees=(-10, 10)),
        ]),
        'image_only': transforms.Compose([
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
    }
    
    transform_eval = {
        'all_channels': transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224, antialias=True),
        ]),
        'image_only': transforms.Compose([
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
    }
    
    return transform_train, transform_eval

def collate_fn(batch):
    """è‡ªå®šä¹‰collateå‡½æ•°ï¼Œè¿‡æ»¤Noneå€¼"""
    batch = list(filter(lambda x: x is not None, batch))
    if len(batch) == 0:
        return None
    return torch.utils.data.default_collate(batch)

def create_sample_data() -> pd.DataFrame:
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    sample_data = {
        'image_path': [
            'sample1.png',
            'sample1.png',  # åŒä¸€å¼ å›¾ç‰‡çš„å¤šä¸ªä¸­å¿ƒç‚¹
            'sample2.png', 
            'sample3.png'
        ],
        'center_x': [100, 200, 150, 300],
        'center_y': [100, 200, 150, 300],
        'patient_id': ['patient_00' + str(i) for i in range(4)], # æ·»åŠ patient_idåˆ—
        'CD3': [0.5, 0.8, 0.3, 0.6],
        'CD8': [0.2, 0.6, 0.4, 0.7],
        'CD20': [0.7, 0.3, 0.9, 0.4],
        'CD68': [0.1, 0.9, 0.2, 0.8]  # æ·»åŠ æ›´å¤šç”Ÿç‰©æ ‡è®°ç‰©
    }
    return pd.DataFrame(sample_data)

def create_rgb_sample_data() -> pd.DataFrame:
    """åˆ›å»ºRGBæ ¼å¼çš„ç¤ºä¾‹æ•°æ®"""
    sample_data = {
        'image_path': [
            'HE/sample1.png',
            'HE/sample1.png',  # åŒä¸€å¼ å›¾ç‰‡çš„å¤šä¸ªä¸­å¿ƒç‚¹
            'CD3/sample2.png', 
            'CD8/sample3.png'
        ],
        'center_x': [100, 200, 150, 300],
        'center_y': [100, 200, 150, 300],
        'patient_id': ['patient_00' + str(i) for i in range(4)],
        # RGBæ ¼å¼çš„ç”Ÿç‰©æ ‡è®°ç‰©
        'HE_R': [120.5, 180.8, 130.3, 160.6],
        'HE_G': [100.2, 160.6, 140.4, 170.7],
        'HE_B': [80.7, 130.3, 190.9, 140.4],
        'CD3_R': [50.1, 90.9, 20.2, 80.8],
        'CD3_G': [40.2, 80.6, 30.4, 70.7],
        'CD3_B': [30.7, 70.3, 40.9, 60.4],
        'CD8_R': [60.5, 80.8, 50.3, 70.6],
        'CD8_G': [50.2, 70.6, 60.4, 80.7],
        'CD8_B': [40.7, 60.3, 70.9, 90.4]
    }
    return pd.DataFrame(sample_data)

def test_dataset_with_real_image(image_path: str, patch_size: int = 128, 
                                use_rgb_format: bool = False, 
                                target_biomarkers: Optional[List[str]] = None):
    """ä½¿ç”¨çœŸå®å›¾åƒæµ‹è¯•æ•°æ®é›†"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•åŸºäºä¸­å¿ƒç‚¹çš„PatchImageDataset")
    print("=" * 60)
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    if use_rgb_format:
        # åˆ›å»ºRGBæ ¼å¼çš„æµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿtma_data.parquetæ ¼å¼ï¼‰
        test_data = pd.DataFrame({
            'image_path': [os.path.basename(image_path)] * 4,  # åŒä¸€å¼ å›¾ç‰‡çš„4ä¸ªä¸­å¿ƒç‚¹
            'center_x': [100, 500, 1000, 2000],  # ä¸åŒçš„ä¸­å¿ƒç‚¹xåæ ‡
            'center_y': [100, 500, 1000, 2000],  # ä¸åŒçš„ä¸­å¿ƒç‚¹yåæ ‡
            'patient_id': ['patient_00' + str(i) for i in range(4)],
            # RGBæ ¼å¼çš„ç”Ÿç‰©æ ‡è®°ç‰©ï¼ˆæ¨¡æ‹Ÿdataframe_generator.pyçš„è¾“å‡ºï¼‰
            'HE_R': [120.5, 180.8, 130.3, 160.6],
            'HE_G': [100.2, 160.6, 140.4, 170.7],
            'HE_B': [80.7, 130.3, 190.9, 140.4],
            'CD3_R': [50.1, 90.9, 20.2, 80.8],
            'CD3_G': [40.2, 80.6, 30.4, 70.7],
            'CD3_B': [30.7, 70.3, 40.9, 60.4],
            'CD8_R': [60.5, 80.8, 50.3, 70.6],
            'CD8_G': [50.2, 70.6, 60.4, 80.7],
            'CD8_B': [40.7, 60.3, 70.9, 90.4],
            'CD56_R': [45.1, 75.9, 35.2, 65.8],
            'CD56_G': [35.2, 65.6, 45.4, 55.7],
            'CD56_B': [25.7, 55.3, 55.9, 45.4]
        })
        print("ğŸ¨ ä½¿ç”¨RGBæ ¼å¼çš„æµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿtma_data.parquetï¼‰")
    else:
        # åˆ›å»ºä¼ ç»Ÿæ ¼å¼çš„æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'image_path': [os.path.basename(image_path)] * 4,  # åŒä¸€å¼ å›¾ç‰‡çš„4ä¸ªä¸­å¿ƒç‚¹
            'center_x': [100, 500, 1000, 2000],  # ä¸åŒçš„ä¸­å¿ƒç‚¹xåæ ‡
            'center_y': [100, 500, 1000, 2000],  # ä¸åŒçš„ä¸­å¿ƒç‚¹yåæ ‡
            'patient_id': ['patient_00' + str(i) for i in range(4)],
            'CD3': [0.5, 0.8, 0.3, 0.6],
            'CD8': [0.2, 0.6, 0.4, 0.7],    # æ·»åŠ æ›´å¤šç”Ÿç‰©æ ‡è®°ç‰©
            'CD20': [0.7, 0.3, 0.9, 0.4],
            'CD68': [0.1, 0.9, 0.2, 0.8]
        })
        print("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿæ ¼å¼çš„æµ‹è¯•æ•°æ®")
    
    # è®¾ç½®æ ¹ç›®å½•
    root_dir = os.path.dirname(image_path)
    
    # åˆ›å»ºæ•°æ®é›†
    print("ğŸ“¦ åˆ›å»ºæ•°æ®é›†...")
    dataset = PatchImageDataset(
        data_df=test_data,
        root_dir=root_dir,
        patch_size=patch_size,
        transform=None,  # ä¸ä½¿ç”¨å˜æ¢ä»¥ä¾¿è§‚å¯ŸåŸå§‹æ•°æ®
        cache_images=True,
        target_biomarkers=target_biomarkers
    )
    
    print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)} ä¸ªæ ·æœ¬")
    print(f"ğŸ§¬ å¯ç”¨ç”Ÿç‰©æ ‡è®°ç‰©: {dataset.available_biomarkers}")
    print(f"ğŸ¯ ç›®æ ‡ç”Ÿç‰©æ ‡è®°ç‰©: {dataset.target_biomarkers}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½...")
    if len(dataset) > 0:
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        sample = dataset[0]
        if sample is not None:
            patch_tensor, exp_vec, valid_mask, center_x, center_y, img_idx = sample
            print(f"âœ… æˆåŠŸåŠ è½½æ ·æœ¬:")
            print(f"   - Patchå½¢çŠ¶: {patch_tensor.shape}")
            print(f"   - ä¸­å¿ƒç‚¹: ({center_x}, {center_y})")
            print(f"   - å›¾åƒç´¢å¼•: {img_idx}")
            print(f"   - è¡¨è¾¾å€¼: {exp_vec}")
            print(f"   - æœ‰æ•ˆæ©ç : {valid_mask}")
        
        # æµ‹è¯•DataLoader
        print("\nğŸ”„ æµ‹è¯•DataLoader...")
        dataloader = DataLoader(
            dataset, 
            batch_size=min(2, len(dataset)), 
            shuffle=False, 
            collate_fn=collate_fn,
            num_workers=0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )
        
        for i, batch in enumerate(dataloader):
            if batch is not None:
                inputs, labels, masks, x_coords, y_coords, img_indices = batch
                print(f"âœ… æ‰¹æ¬¡ {i}:")
                print(f"   - è¾“å…¥å½¢çŠ¶: {inputs.shape}")
                print(f"   - æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
                print(f"   - æ©ç å½¢çŠ¶: {masks.shape}")
                print(f"   - ä¸­å¿ƒç‚¹åæ ‡: x={x_coords.tolist()}, y={y_coords.tolist()}")
                break
            else:
                print(f"âš ï¸ æ‰¹æ¬¡ {i} ä¸ºç©º")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")

def test_with_parquet_file(parquet_path: str, image_root_dir: str = None, 
                          patch_size: int = 128, 
                          target_biomarkers: Optional[List[str]] = None,
                          subset: Optional[List[str]] = None,
                          use_zarr: bool = True,
                          zarr_marker: str = 'HE'):
    """ä½¿ç”¨parquetæ–‡ä»¶æµ‹è¯•æ•°æ®é›†ï¼ˆæµå¼è¯»å–ï¼‰"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•åŸºäºparquetæ–‡ä»¶çš„æµå¼PatchImageDataset")
    print("=" * 60)
    
    if not os.path.exists(parquet_path):
        print(f"âŒ Parquetæ–‡ä»¶ä¸å­˜åœ¨: {parquet_path}")
        return
    
    # åˆ›å»ºæµå¼æ•°æ®é›†
    print("ğŸ“¦ åˆ›å»ºæµå¼æ•°æ®é›†...")
    try:
        dataset = PatchImageDataset(
            parquet_path=parquet_path,
            root_dir=image_root_dir,
            patch_size=patch_size,
            transform=None,  # ä¸ä½¿ç”¨å˜æ¢ä»¥ä¾¿è§‚å¯ŸåŸå§‹æ•°æ®
            cache_images=False,  # å¯¹äºå¤§æ•°æ®é›†ï¼Œä¸ç¼“å­˜å›¾åƒ
            target_biomarkers=target_biomarkers,
            subset=subset,  # å­é›†è¿‡æ»¤
            use_zarr=use_zarr,  # ä½¿ç”¨zarråŠ è½½
            zarr_marker=zarr_marker  # zarr marker
        )
        
        print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)} ä¸ªæ ·æœ¬")
        print(f"ğŸ¯ ç›®æ ‡ç”Ÿç‰©æ ‡è®°ç‰©: {dataset.target_biomarkers}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½...")
        if len(dataset) > 0:
            # æµ‹è¯•å•ä¸ªæ ·æœ¬
            sample = dataset[0]
            if sample is not None:
                patch_tensor, exp_vec, valid_mask, center_x, center_y, img_idx = sample
                print(f"âœ… æˆåŠŸåŠ è½½æ ·æœ¬:")
                print(f"   - Patchå½¢çŠ¶: {patch_tensor.shape}")
                print(f"   - ä¸­å¿ƒç‚¹: ({center_x}, {center_y})")
                print(f"   - å›¾åƒç´¢å¼•: {img_idx}")
                print(f"   - è¡¨è¾¾å€¼å½¢çŠ¶: {exp_vec.shape}")
                print(f"   - è¡¨è¾¾å€¼: {exp_vec}")
                print(f"   - æœ‰æ•ˆæ©ç å½¢çŠ¶: {valid_mask.shape}")
                print(f"   - æœ‰æ•ˆæ©ç : {valid_mask}")
            
            # æµ‹è¯•DataLoader
            print("\nğŸ”„ æµ‹è¯•DataLoader...")
            dataloader = DataLoader(
                dataset, 
                batch_size=min(2, len(dataset)), 
                shuffle=False, 
                collate_fn=collate_fn,
                num_workers=0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
            )
            
            for i, batch in enumerate(dataloader):
                if batch is not None:
                    inputs, labels, masks, x_coords, y_coords, img_indices = batch
                    print(f"âœ… æ‰¹æ¬¡ {i}:")
                    print(f"   - è¾“å…¥å½¢çŠ¶: {inputs.shape}")
                    print(f"   - æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
                    print(f"   - æ©ç å½¢çŠ¶: {masks.shape}")
                    print(f"   - ä¸­å¿ƒç‚¹åæ ‡: x={x_coords.tolist()}, y={y_coords.tolist()}")
                    break
                else:
                    print(f"âš ï¸ æ‰¹æ¬¡ {i} ä¸ºç©º")
        
        print("\nâœ… æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ•°æ®é›†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åŸºäºä¸­å¿ƒç‚¹çš„Patchæ•°æ®é›†æµ‹è¯•')
    parser.add_argument('--image', type=str, help='æµ‹è¯•å›¾åƒè·¯å¾„')
    parser.add_argument('--parquet', type=str, help='parquetæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--image-root', type=str, help='å›¾åƒæ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--patch-size', type=int, default=128, help='patchå°ºå¯¸')
    parser.add_argument('--rgb-format', action='store_true', help='ä½¿ç”¨RGBæ ¼å¼çš„æµ‹è¯•æ•°æ®')
    parser.add_argument('--target-biomarkers', nargs='+', help='ç›®æ ‡ç”Ÿç‰©æ ‡è®°ç‰©åˆ—è¡¨ï¼Œä¾‹å¦‚: --target-biomarkers CD3 CD8')
    parser.add_argument('--subset', nargs='+', help='å­é›†è¡Œç´¢å¼•åˆ—è¡¨ï¼Œä¾‹å¦‚: --subset 0 1 2 100 200')
    parser.add_argument('--use-zarr', action='store_true', default=True, help='ä½¿ç”¨zarrç›´æ¥åŠ è½½ï¼ˆé»˜è®¤: Trueï¼‰')
    parser.add_argument('--use-image-files', action='store_true', help='ä½¿ç”¨å›¾åƒæ–‡ä»¶åŠ è½½ï¼ˆè¦†ç›–zarrè®¾ç½®ï¼‰')
    parser.add_argument('--zarr-marker', type=str, default='HE', help='ç”¨äºåŠ è½½å›¾åƒçš„zarr markeråç§°ï¼ˆé»˜è®¤: HEï¼‰')
    
    args = parser.parse_args()
    
    if args.parquet:
        # ä½¿ç”¨parquetæ–‡ä»¶æµ‹è¯•ï¼ˆæµå¼è¯»å–ï¼‰
        use_zarr = args.use_zarr and not args.use_image_files
        test_with_parquet_file(
            args.parquet, 
            args.image_root, 
            args.patch_size, 
            args.target_biomarkers, 
            args.subset,
            use_zarr,
            args.zarr_marker
        )
    elif args.image:
        # ä½¿ç”¨å•å¼ å›¾åƒæµ‹è¯•
        test_dataset_with_real_image(args.image, args.patch_size, args.rgb_format, args.target_biomarkers)
    else:
        print("âŒ è¯·æä¾›æµ‹è¯•å‚æ•°")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  # ä½¿ç”¨å•å¼ å›¾åƒæµ‹è¯•:")
        print("  python patch_dataset.py --image /path/to/image.png")
        print("  python patch_dataset.py --image /path/to/image.png --rgb-format")
        print("  python patch_dataset.py --image /path/to/image.png --rgb-format --target-biomarkers CD3 CD8")
        print("  # ä½¿ç”¨parquetæ–‡ä»¶æµ‹è¯•ï¼ˆæµå¼è¯»å–ï¼‰:")
        print("  # Zarrç›´æ¥åŠ è½½ï¼ˆæ¨èï¼Œé€Ÿåº¦å¿«ï¼‰:")
        print("  python patch_dataset.py --parquet /path/to/data.parquet")
        print("  python patch_dataset.py --parquet /path/to/data.parquet --target-biomarkers CD3 CD8")
        print("  python patch_dataset.py --parquet /path/to/data.parquet --zarr-marker CD3")
        print("  # ä¼ ç»Ÿå›¾åƒæ–‡ä»¶åŠ è½½:")
        print("  python patch_dataset.py --parquet /path/to/data.parquet --image-root /path/to/images --use-image-files")
        print("  # å…¶ä»–é€‰é¡¹:")
        print("  python patch_dataset.py --parquet /path/to/data.parquet --subset 0 1 2 100 200")

if __name__ == '__main__':
    main()
