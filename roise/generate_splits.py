#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„æ•°æ®åˆ†å‰²ç´¢å¼•ç”Ÿæˆè„šæœ¬
"""

import argparse
import numpy as np
import pandas as pd

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç”Ÿæˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ç´¢å¼•åˆ†å‰²")
    parser.add_argument("--data-file", required=True, help="æ•°æ®parquetæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--split-ratios", nargs=3, type=float, default=[0.7, 0.15, 0.15], 
                        help="è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†æ¯”ä¾‹ [train val test]")
    parser.add_argument("--split-seed", type=int, default=42, help="æ•°æ®åˆ†å‰²éšæœºç§å­")
    parser.add_argument("--output", type=str, default="data_splits.npz", help="è¾“å‡ºæ–‡ä»¶å")
    
    args = parser.parse_args()
    
    print("ğŸš€ æ•°æ®åˆ†å‰²ç´¢å¼•ç”Ÿæˆå™¨")
    print("=" * 50)
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {args.data_file}")
    print(f"ğŸ“Š åˆ†å‰²æ¯”ä¾‹: {args.split_ratios}")
    print(f"ğŸ² éšæœºç§å­: {args.split_seed}")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {args.output}")
    print()
    
    # ç”Ÿæˆåˆ†å‰²
    print("ğŸ“Š ç”Ÿæˆæ•°æ®åˆ†å‰²ç´¢å¼•...")
    
    # è¯»å–æ•°æ®æ–‡ä»¶è·å–æ€»æ ·æœ¬æ•°
    df = pd.read_parquet(args.data_file)
    total_samples = len(df)
    
    print(f"ğŸ“ˆ æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"ğŸ“Š åˆ†å‰²æ¯”ä¾‹: è®­ç»ƒ={args.split_ratios[0]:.1%}, éªŒè¯={args.split_ratios[1]:.1%}, æµ‹è¯•={args.split_ratios[2]:.1%}")
    
    # éªŒè¯åˆ†å‰²æ¯”ä¾‹
    if abs(sum(args.split_ratios) - 1.0) > 1e-6:
        raise ValueError(f"åˆ†å‰²æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ä¸º1.0ï¼Œå½“å‰ä¸º: {sum(args.split_ratios)}")
    
    # ç”Ÿæˆç´¢å¼•
    indices = np.arange(total_samples)
    
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    np.random.seed(args.split_seed)
    np.random.shuffle(indices)
    
    # è®¡ç®—åˆ†å‰²ç‚¹
    train_size = int(total_samples * args.split_ratios[0])
    val_size = int(total_samples * args.split_ratios[1])
    
    # åˆ†å‰²ç´¢å¼•
    train_indices = indices[:train_size]
    val_indices = indices[train_size:train_size + val_size]
    test_indices = indices[train_size + val_size:]
    
    print(f"âœ… è®­ç»ƒé›†ç´¢å¼•: {len(train_indices)} ä¸ªæ ·æœ¬")
    print(f"âœ… éªŒè¯é›†ç´¢å¼•: {len(val_indices)} ä¸ªæ ·æœ¬")
    print(f"âœ… æµ‹è¯•é›†ç´¢å¼•: {len(test_indices)} ä¸ªæ ·æœ¬")
    
    # ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶
    np.savez_compressed(
        args.output,
        train_indices=train_indices,
        val_indices=val_indices,
        test_indices=test_indices,
        split_ratios=args.split_ratios,
        split_seed=args.split_seed,
        total_samples=total_samples
    )
    print(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ°: {args.output}")
    
    # ä¿å­˜ä¸ºCSVæ ¼å¼ä¾¿äºæŸ¥çœ‹
    csv_file = args.output.replace('.npz', '.csv')
    split_df = pd.DataFrame({
        'index': np.concatenate([train_indices, val_indices, test_indices]),
        'split': ['train'] * len(train_indices) + ['val'] * len(val_indices) + ['test'] * len(test_indices)
    })
    split_df = split_df.sort_values('index').reset_index(drop=True)
    split_df.to_csv(csv_file, index=False)
    print(f"ğŸ“‹ CSVæ ¼å¼å·²ä¿å­˜åˆ°: {csv_file}")
    
    print("\nğŸ‰ æ•°æ®åˆ†å‰²å®Œæˆï¼")
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"   - è®­ç»ƒé›†: {len(train_indices)} ä¸ªæ ·æœ¬ ({len(train_indices)/total_samples:.1%})")
    print(f"   - éªŒè¯é›†: {len(val_indices)} ä¸ªæ ·æœ¬ ({len(val_indices)/total_samples:.1%})")
    print(f"   - æµ‹è¯•é›†: {len(test_indices)} ä¸ªæ ·æœ¬ ({len(test_indices)/total_samples:.1%})")
    print(f"   - æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"   - éšæœºç§å­: {args.split_seed}")
    print(f"   - åˆ†å‰²æ¯”ä¾‹: {args.split_ratios}")

if __name__ == "__main__":
    main()
